#!/usr/bin/env python3
"""
Telegram Messages Data Extractor using OpenRouter API.
Processes CSV files from telegram_parser.py and extracts structured insights using LLM.

Usage Examples:
---------------

# Basic extraction (process all files from 001 to 043)
python extract_data.py messages_001.csv messages_043.csv

# Process specific range with custom output directory
python extract_data.py export/messages_001.csv export/messages_010.csv \
    --output-dir analysis/

# Full debug mode (all features for testing)
python extract_data.py messages_001.csv messages_005.csv \
    --save-responses \
    --interactive \
    --output-dir debug_output/

# Production run with auto-confirmation
python extract_data.py messages_001.csv messages_043.csv \
    --output-dir results/ \
    --yes

# Custom prompt template
python extract_data.py messages_001.csv messages_010.csv \
    --prompt-file custom_extract_prompt.md \
    --save-responses

# Skip already processed files
python extract_data.py messages_001.csv messages_043.csv \
    --skip-existing \
    --output-dir analysis/

# All parameters example
python extract_data.py export/messages_001.csv export/messages_043.csv \
    --output-dir output/ \
    --prompt-file extract-prompt.md \
    --save-responses \
    --interactive \
    --skip-existing \
    --yes

Parameters:
-----------
  start                 Start CSV file (e.g., messages_001.csv)
  end                   End CSV file (e.g., messages_043.csv)
  --output-dir DIR      Output directory for analysis files (default: current directory)
  --prompt-file FILE    Path to prompt template (default: extract-prompt.md)
  --save-responses      Save raw API responses for debugging
  --interactive         Pause after each extraction for user confirmation
  --skip-existing       Skip files that already have analysis output
  -y, --yes            Skip initial file list confirmation

Notes:
------
- Processes only 'text' column from CSV files
- Creates analysis_NNN.md files from messages_NNN.csv files
- Uses same OpenRouter API configuration as merge_files.py
- Retries 3 times on failure, then stops completely
- Overwrites existing analysis files unless --skip-existing is used
"""

import os
import sys
import json
import csv
import time
import argparse
import re
import warnings
from pathlib import Path
from typing import List, Optional, Dict

# Suppress the urllib3 OpenSSL warning
warnings.filterwarnings('ignore', message='urllib3 v2 only supports OpenSSL')

import requests
from dotenv import load_dotenv


class DataExtractor:
    def __init__(self, args):
        """Initialize the extractor with configuration."""
        self.args = args
        self.load_config()
        self.files_to_process = []
        self.current_file_index = 0
        
    def load_config(self):
        """Load configuration from .env file."""
        load_dotenv()
        
        # API Configuration (same as merge_files.py)
        self.api_key = os.getenv('OPENROUTER_API_KEY')
        if not self.api_key:
            print("‚ùå Error: OPENROUTER_API_KEY not found in .env file")
            sys.exit(1)
            
        self.api_url = os.getenv('OPENROUTER_API_URL', 'https://openrouter.ai/api/v1/chat/completions')
        self.model = os.getenv('OPENROUTER_MODEL', 'qwen/qwen-2.5-72b-instruct')
        self.temperature = float(os.getenv('OPENROUTER_TEMPERATURE', '0.3'))
        self.max_retries = int(os.getenv('OPENROUTER_MAX_RETRIES', '3'))
        self.retry_delay = int(os.getenv('OPENROUTER_RETRY_DELAY', '5'))
        
        # Max tokens - None means no limit
        max_tokens_str = os.getenv('OPENROUTER_MAX_TOKENS', 'none')
        self.max_tokens = None if max_tokens_str.lower() == 'none' else int(max_tokens_str)
        
        print(f"‚úì Configuration loaded")
        print(f"  Model: {self.model}")
        print(f"  Temperature: {self.temperature}")
        print(f"  Max tokens: {'unlimited' if self.max_tokens is None else self.max_tokens}")
        print()
        
    def discover_files(self) -> List[Path]:
        """Discover CSV files to process based on start and end parameters."""
        start_path = Path(self.args.start)
        end_path = Path(self.args.end)
        
        if not start_path.exists():
            print(f"‚ùå Error: Start file not found: {start_path}")
            sys.exit(1)
            
        if not end_path.exists():
            print(f"‚ùå Error: End file not found: {end_path}")
            sys.exit(1)
            
        # Extract pattern from filenames
        start_name = start_path.stem
        end_name = end_path.stem
        
        # Extract number from filename (assumes pattern like messages_NNN)
        start_match = re.search(r'_(\d+)$', start_name)
        end_match = re.search(r'_(\d+)$', end_name)
        
        if not start_match or not end_match:
            print("‚ùå Error: Could not extract numbers from filenames")
            print("  Expected pattern: messages_NNN.csv")
            sys.exit(1)
            
        start_num = int(start_match.group(1))
        end_num = int(end_match.group(1))
        
        # Extract base name (everything before _NNN)
        base_name = start_name[:start_match.start()]
        extension = start_path.suffix
        directory = start_path.parent
        
        # Determine order
        if start_num > end_num:
            step = -1
            nums = range(start_num, end_num - 1, step)
        else:
            step = 1
            nums = range(start_num, end_num + 1, step)
            
        # Collect existing files
        files = []
        for num in nums:
            file_path = directory / f"{base_name}_{num:03d}{extension}"
            if file_path.exists():
                files.append(file_path)
            else:
                print(f"  ‚ö†Ô∏è  Skipping missing file: {file_path.name}")
                
        return files
        
    def show_files_for_confirmation(self, files: List[Path]) -> bool:
        """Display discovered files and ask for confirmation."""
        print("üìÅ CSV files to process (in order):")
        print("-" * 50)
        
        total_messages = 0
        for i, file_path in enumerate(files, 1):
            size = file_path.stat().st_size
            size_kb = size / 1024
            
            # Count messages in file
            message_count = self.count_messages_in_csv(file_path)
            total_messages += message_count
            
            # Check if output exists
            output_file = self.get_output_filename(file_path)
            exists_marker = " [‚úì exists]" if output_file.exists() else ""
            
            print(f"  {i:2d}. {file_path.name:30s} ({size_kb:8.1f} KB, {message_count:4d} messages){exists_marker}")
            
        print("-" * 50)
        print(f"  Total files: {len(files)}")
        print(f"  Total messages: {total_messages}")
        
        if self.args.skip_existing:
            existing_count = sum(1 for f in files if self.get_output_filename(f).exists())
            print(f"  Will skip {existing_count} existing analysis files")
        
        print()
        
        if self.args.yes:
            return True
            
        response = input("Proceed with extraction? (y/n): ").strip().lower()
        return response == 'y'
        
    def count_messages_in_csv(self, file_path: Path) -> int:
        """Count non-empty messages in a CSV file."""
        count = 0
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    if row.get('text', '').strip():
                        count += 1
        except Exception:
            pass
        return count
        
    def load_prompt_template(self) -> str:
        """Load the prompt template from file."""
        prompt_file = Path(self.args.prompt_file)
        
        if not prompt_file.exists():
            print(f"‚ùå Error: Prompt file not found: {prompt_file}")
            print("  Creating default prompt template...")
            self.create_default_prompt_template(prompt_file)
            print(f"  ‚úì Created {prompt_file}")
            print("  Please review and adjust the prompt if needed, then run again.")
            sys.exit(0)
            
        with open(prompt_file, 'r', encoding='utf-8') as f:
            template = f.read()
            
        # Check for required placeholder
        if '{messages_content}' not in template:
            print("‚ùå Error: Prompt template must contain {messages_content} placeholder")
            sys.exit(1)
            
        return template
        
    def create_default_prompt_template(self, prompt_file: Path):
        """Create a default extraction prompt template."""
        default_prompt = """# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∞–Ω–∞–ª–∏–∑—É —Å–æ–æ–±—â–µ–Ω–∏–π

–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ Telegram-–∫–∞–Ω–∞–ª–æ–≤ adult-–∏–Ω–¥—É—Å—Ç—Ä–∏–∏.

## –°–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
{messages_content}

## –¢–≤–æ—è –∑–∞–¥–∞—á–∞:
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∏–∑–≤–ª–µ–∫–∏ –∏–∑ –Ω–∏—Ö —Ü–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–≤ –µ—ë –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ.

## –ß—Ç–æ –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å:
1. **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã –∏ –ª–∞–π—Ñ—Ö–∞–∫–∏** - –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ä–∞–±–æ—Ç–µ –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞—Ö, –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—é, –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏
2. **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏** - –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, —Å–µ—Ä–≤–∏—Å—ã, –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
3. **–§–∏–Ω–∞–Ω—Å–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è** - —Ü–µ–Ω—ã, –¥–æ—Ö–æ–¥—ã, —Ä–∞—Å—Ü–µ–Ω–∫–∏, –ø—Ä–æ—Ü–µ–Ω—Ç—ã –∫–æ–º–∏—Å—Å–∏–π
4. **–ò—Å—Ç–æ—Ä–∏–∏ –∏ –∫–µ–π—Å—ã** - —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã —É—Å–ø–µ—Ö–æ–≤ –∏ –Ω–µ—É–¥–∞—á —Å –¥–µ—Ç–∞–ª—è–º–∏
5. **–¢—Ä–µ–Ω–¥—ã –∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è** - –Ω–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º, –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö, –Ω–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
6. **–ü—Ä–æ–±–ª–µ–º—ã –∏ —Ä–µ—à–µ–Ω–∏—è** - —Ç–∏–ø–∏—á–Ω—ã–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏ —Å–ø–æ—Å–æ–±—ã –∏—Ö –ø—Ä–µ–æ–¥–æ–ª–µ–Ω–∏—è
7. **–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏ —Å–µ—Ä–≤–∏—Å—ã** - –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è, —Å—Å—ã–ª–∫–∏, –æ–ø–∏—Å–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–π

## –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É:
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞–∑–¥–µ–ª–∞–º —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
- –°–æ—Ö—Ä–∞–Ω—è–π –í–°–ï –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ—Ç–∞–ª–∏: –Ω–∞–∑–≤–∞–Ω–∏—è, —á–∏—Å–ª–∞, –ø—Ä–æ—Ü–µ–Ω—Ç—ã, –¥–∞—Ç—ã, —Å—É–º–º—ã
- –ò—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏ –∏ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è —É–¥–æ–±–Ω–æ–π –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
- –ü–∏—à–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
- –§–æ—Ä–º–∞—Ç: Markdown
- –ù–ï –æ–±–æ–±—â–∞–π –∏ –Ω–µ —É–ø—Ä–æ—â–∞–π - —Å–æ—Ö—Ä–∞–Ω—è–π –º–∞–∫—Å–∏–º—É–º –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏
- –ï—Å–ª–∏ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö –µ—Å—Ç—å —Å—Å—ã–ª–∫–∏, —Å–æ—Ö—Ä–∞–Ω—è–π –∏—Ö

## –í–∞–∂–Ω–æ:
- –í—ã–≤–æ–¥–∏ –¢–û–õ–¨–ö–û —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
- –ù–ï –¥–æ–±–∞–≤–ª—è–π –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è —Ç–∏–ø–∞ "–í–æ—Ç –∞–Ω–∞–ª–∏–∑..." –∏–ª–∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è
- –ù–ï –¥–æ–±–∞–≤–ª—è–π –º–µ—Ç–∞-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ –ø—Ä–æ—Ü–µ—Å—Å–µ –∞–Ω–∞–ª–∏–∑–∞
- –ù–∞—á–∏–Ω–∞–π —Å—Ä–∞–∑—É —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
        
        with open(prompt_file, 'w', encoding='utf-8') as f:
            f.write(default_prompt)
            
    def extract_messages_from_csv(self, csv_path: Path) -> str:
        """Extract text messages from CSV file."""
        messages = []
        
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    text = row.get('text', '').strip()
                    if text:
                        # Replace escaped newlines with actual newlines
                        text = text.replace('\\n', '\n')
                        messages.append(text)
                        
        except Exception as e:
            print(f"  ‚ùå Error reading CSV file: {str(e)}")
            return ""
            
        # Join messages with clear separators
        return "\n\n---\n\n".join(messages)
        
    def call_openrouter_api(self, prompt: str, file_index: int) -> Optional[str]:
        """Call OpenRouter API with the extraction prompt."""
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json',
            'HTTP-Referer': 'https://github.com/user/telegram-extractor',
            'X-Title': 'Telegram Data Extractor'
        }
        
        payload = {
            'model': self.model,
            'messages': [
                {
                    'role': 'system',
                    'content': '–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫, –∏–∑–≤–ª–µ–∫–∞—é—â–∏–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π. –í—ã–≤–æ–¥–∏ —Ç–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑ –º–µ—Ç–∞-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤.'
                },
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            'temperature': self.temperature
        }
        
        if self.max_tokens is not None:
            payload['max_tokens'] = self.max_tokens
            
        for attempt in range(self.max_retries):
            response = None
            try:
                print(f"  üì° Calling API (attempt {attempt + 1}/{self.max_retries})...")
                response = requests.post(
                    self.api_url,
                    headers=headers,
                    json=payload,
                    timeout=300  # 5 minute timeout
                )
                
                if response.status_code == 200:
                    try:
                        data = response.json()
                        
                        # Save raw response if configured
                        if self.args.save_responses:
                            response_file = self.get_output_path(f"response_file_{file_index:03d}_attempt_{attempt + 1}.json")
                            with open(response_file, 'w', encoding='utf-8') as f:
                                json.dump(data, f, indent=2, ensure_ascii=False)
                                
                        # Extract content
                        if 'choices' in data and len(data['choices']) > 0:
                            content = data['choices'][0]['message']['content']
                            return content
                        else:
                            print(f"  ‚ö†Ô∏è  Unexpected API response structure")
                            
                    except json.JSONDecodeError as e:
                        print(f"  ‚ö†Ô∏è  Invalid JSON response: {str(e)}")
                        
                else:
                    print(f"  ‚ö†Ô∏è  API error: {response.status_code}")
                    print(f"     Response: {response.text[:200]}...")
                    
            except requests.exceptions.Timeout:
                print(f"  ‚ö†Ô∏è  Request timeout")
            except Exception as e:
                print(f"  ‚ö†Ô∏è  Error: {str(e)}")
                
            if attempt < self.max_retries - 1:
                print(f"  ‚è≥ Waiting {self.retry_delay} seconds before retry...")
                time.sleep(self.retry_delay)
                
        return None
        
    def get_output_path(self, filename: str) -> Path:
        """Get the output file path."""
        if self.args.output_dir:
            output_dir = Path(self.args.output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            return output_dir / filename
        else:
            return Path(filename)
            
    def get_output_filename(self, csv_path: Path) -> Path:
        """Generate output filename from CSV filename."""
        # Extract number from messages_NNN.csv
        csv_name = csv_path.stem
        match = re.search(r'_(\d+)$', csv_name)
        
        if match:
            number = match.group(1)
            output_name = f"analysis_{number}.md"
        else:
            # Fallback if pattern doesn't match
            output_name = f"analysis_{csv_name}.md"
            
        return self.get_output_path(output_name)
        
    def process_csv_file(self, csv_path: Path, file_index: int) -> bool:
        """Process a single CSV file and generate analysis."""
        output_file = self.get_output_filename(csv_path)
        
        # Check if should skip
        if self.args.skip_existing and output_file.exists():
            print(f"  ‚è≠Ô∏è  Skipping (already exists): {output_file.name}")
            return True
            
        print(f"\nüìù Processing: {csv_path.name}")
        
        # Extract messages
        messages_content = self.extract_messages_from_csv(csv_path)
        
        if not messages_content:
            print(f"  ‚ö†Ô∏è  No messages found in {csv_path.name}")
            return True  # Not a failure, just empty
            
        message_count = len(messages_content.split('\n\n---\n\n'))
        print(f"  Found {message_count} messages")
        print(f"  Total content: {len(messages_content)} characters")
        
        # Prepare prompt
        prompt = self.prompt_template.replace('{messages_content}', messages_content)
        
        # Call API
        result = self.call_openrouter_api(prompt, file_index)
        
        if result is None:
            print(f"  ‚ùå API call failed after all retries")
            return False
            
        # Save result
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(result)
            
        print(f"  üíæ Saved: {output_file} ({len(result)} characters)")
        
        return True
        
    def run(self):
        """Main execution flow."""
        print("üöÄ Data Extractor Starting")
        print("=" * 60)
        
        # Discover files
        files = self.discover_files()
        
        if not files:
            print("‚ùå Error: No files found to process")
            sys.exit(1)
            
        # Show files and get confirmation
        if not self.show_files_for_confirmation(files):
            print("‚ùå Extraction cancelled by user")
            sys.exit(0)
            
        # Load prompt template
        self.prompt_template = self.load_prompt_template()
        print(f"‚úì Prompt template loaded from: {self.args.prompt_file}")
        
        # Process each file
        total_files = len(files)
        successful = 0
        failed = 0
        skipped = 0
        
        for i, csv_file in enumerate(files, 1):
            self.current_file_index = i
            
            print(f"\n{'=' * 60}")
            print(f"File {i}/{total_files}: {csv_file.name}")
            print(f"{'=' * 60}")
            
            # Check if should skip
            output_file = self.get_output_filename(csv_file)
            if self.args.skip_existing and output_file.exists():
                print(f"‚è≠Ô∏è  Skipping existing file: {output_file.name}")
                skipped += 1
                continue
            
            # Process file
            success = self.process_csv_file(csv_file, i)
            
            if success:
                successful += 1
            else:
                failed += 1
                print(f"\n‚ùå Extraction failed for {csv_file.name}")
                print(f"   Stopping process due to failure.")
                break
                
            # Interactive mode
            if self.args.interactive and i < total_files:
                print(f"\n‚è∏Ô∏è  File {i} completed. Press Enter to continue or Ctrl+C to stop...")
                input()
                
        # Summary
        print(f"\n{'=' * 60}")
        print(f"‚úÖ Extraction completed!")
        print(f"   Successful: {successful}")
        print(f"   Failed: {failed}")
        print(f"   Skipped: {skipped}")
        print(f"   Total processed: {successful + failed + skipped}/{total_files}")
        
        if failed > 0:
            print(f"\n‚ö†Ô∏è  Some files failed to process.")
            print(f"   You can retry with the same command.")
            sys.exit(1)


def main():
    parser = argparse.ArgumentParser(
        description='Extract structured data from Telegram message CSV files using LLM',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s messages_001.csv messages_043.csv
  %(prog)s messages_001.csv messages_010.csv --save-responses
  %(prog)s export/messages_001.csv export/messages_043.csv --output-dir analysis/
  %(prog)s messages_001.csv messages_005.csv --interactive --skip-existing
"""
    )
    
    # Required arguments
    parser.add_argument('start', help='Start CSV file (e.g., messages_001.csv)')
    parser.add_argument('end', help='End CSV file (e.g., messages_043.csv)')
    
    # Optional arguments
    parser.add_argument('--output-dir', help='Output directory for analysis files (default: current directory)')
    parser.add_argument('--prompt-file', default='extract-prompt.md', 
                        help='Path to prompt template file (default: extract-prompt.md)')
    parser.add_argument('--save-responses', action='store_true',
                        help='Save raw API responses for debugging')
    parser.add_argument('--interactive', action='store_true',
                        help='Pause after each extraction for user confirmation')
    parser.add_argument('--skip-existing', action='store_true',
                        help='Skip files that already have analysis output')
    parser.add_argument('-y', '--yes', action='store_true',
                        help='Skip confirmation prompt')
    
    args = parser.parse_args()
    
    # Run extractor
    extractor = DataExtractor(args)
    
    try:
        extractor.run()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Extraction interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Unexpected error: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()